{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqXi0H999KK7",
        "outputId": "40c92a32-bdeb-4d77-b1db-590432a8d321"
      },
      "id": "GqXi0H999KK7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "project_path = '/content/drive/MyDrive/BLG454EProject'\n",
        "os.chdir(project_path)\n",
        "\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QE5m61Ef9akc",
        "outputId": "1c1c32c1-eef7-4cd7-9a32-f0b5725c0688"
      },
      "id": "QE5m61Ef9akc",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cifar10_train_eval.ipynb  fashion_train_eval.ipynb\n",
            "distiller\t\t  mnist_train_eval.ipynb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf30daf6",
      "metadata": {
        "id": "bf30daf6"
      },
      "source": [
        "This notebook compares how well a simple **LeNet** model performs when trained on:\n",
        "1. The **full** MNIST training set (60 k images)\n",
        "2. A **randomly‑sampled** subset containing **10 images per class** (100 images total)\n",
        "3. A **distilled** synthetic set generated with Gradient Matching\n",
        "\n",
        "We evaluate each model on the **canonical MNIST test split (10 k images)** and summarise the results.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d0551cf9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0551cf9",
        "outputId": "3a7d5c71-2659-4295-b171-fde899a69023"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import os, random, math, time, copy\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
        "from torchvision import datasets, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from distiller.models.LeNet import LeNet\n",
        "\n",
        "# Reproducibility\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed_all(SEED)\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('Using device:', device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ac9e4725",
      "metadata": {
        "id": "ac9e4725"
      },
      "outputs": [],
      "source": [
        "def train(model, loader, criterion, optimizer, epochs=5, log_interval=100):\n",
        "    model.train()\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        running_loss = 0.0\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader, 1):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item()\n",
        "            if batch_idx % log_interval == 0 or batch_idx == len(loader):\n",
        "                print(f'Epoch {epoch}/{epochs} | Batch {batch_idx}/{len(loader)} | Loss: {running_loss / batch_idx:.4f}', end='\\r')\n",
        "        print(f'Epoch {epoch} finished. Avg Loss: {running_loss / len(loader):.4f}')\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            preds = outputs.argmax(dim=1)\n",
        "            correct += (preds == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "    return 100.0 * correct / total\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "540b8b09",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "540b8b09",
        "outputId": "79bf7f30-bb4a-43f1-8a97-870c2e6bda3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full training set size: 60000\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "])\n",
        "\n",
        "root = Path('distiller/data')\n",
        "full_train = datasets.MNIST(root, train=True, download=True, transform=transform)\n",
        "test_set = datasets.MNIST(root, train=False, download=True, transform=transform)\n",
        "\n",
        "test_loader = DataLoader(test_set, batch_size=512, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "print(f'Full training set size: {len(full_train)}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5bd96f0",
      "metadata": {
        "id": "b5bd96f0"
      },
      "source": [
        "## Training on the **full** MNIST training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5b940a64",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b940a64",
        "outputId": "e1ece198-df4b-44f5-fa22-8a30d0addeb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished. Avg Loss: 0.3011\n",
            "\n",
            "Test accuracy (full data): 97.00%\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE_FULL = 128\n",
        "EPOCHS_FULL = 1\n",
        "\n",
        "full_loader = DataLoader(full_train, batch_size=BATCH_SIZE_FULL, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "model_full = LeNet().to(device)\n",
        "optimizer = optim.Adam(model_full.parameters(), lr=1e-3)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train(model_full, full_loader, criterion, optimizer, epochs=EPOCHS_FULL, log_interval=200)\n",
        "acc_full = evaluate(model_full, test_loader)\n",
        "print(f'\\nTest accuracy (full data): {acc_full:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18aa9279",
      "metadata": {
        "id": "18aa9279"
      },
      "source": [
        "## Training on a **random** subset (10 images × 10 classes = 100 images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6b818a45",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b818a45",
        "outputId": "39a49b5a-5e52-45e9-d426-c29ca582513c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subset size: 100\n",
            "Epoch 1 finished. Avg Loss: 2.2823\n",
            "Epoch 2 finished. Avg Loss: 2.2360\n",
            "Epoch 3 finished. Avg Loss: 2.1785\n",
            "Epoch 4 finished. Avg Loss: 2.1191\n",
            "Epoch 5 finished. Avg Loss: 1.9601\n",
            "Epoch 6 finished. Avg Loss: 1.8343\n",
            "Epoch 7 finished. Avg Loss: 1.6432\n",
            "Epoch 8 finished. Avg Loss: 1.4877\n",
            "Epoch 9 finished. Avg Loss: 1.3013\n",
            "Epoch 10 finished. Avg Loss: 1.0846\n",
            "Epoch 11 finished. Avg Loss: 0.9049\n",
            "Epoch 12 finished. Avg Loss: 0.6701\n",
            "Epoch 13 finished. Avg Loss: 0.6481\n",
            "Epoch 14 finished. Avg Loss: 0.5000\n",
            "Epoch 15 finished. Avg Loss: 0.4231\n",
            "Epoch 16 finished. Avg Loss: 0.5859\n",
            "Epoch 17 finished. Avg Loss: 0.4004\n",
            "Epoch 18 finished. Avg Loss: 0.2917\n",
            "Epoch 19 finished. Avg Loss: 0.2355\n",
            "Epoch 20 finished. Avg Loss: 0.2816\n",
            "Epoch 21 finished. Avg Loss: 0.2421\n",
            "Epoch 22 finished. Avg Loss: 0.1473\n",
            "Epoch 23 finished. Avg Loss: 0.1507\n",
            "Epoch 24 finished. Avg Loss: 0.1070\n",
            "Epoch 25 finished. Avg Loss: 0.1338\n",
            "Epoch 26 finished. Avg Loss: 0.1013\n",
            "Epoch 27 finished. Avg Loss: 0.0707\n",
            "Epoch 28 finished. Avg Loss: 0.0651\n",
            "Epoch 29 finished. Avg Loss: 0.0625\n",
            "Epoch 30 finished. Avg Loss: 0.0395\n",
            "\n",
            "Test accuracy (random 100 examples): 78.31%\n"
          ]
        }
      ],
      "source": [
        "def stratified_random_subset(dataset, per_class=10):\n",
        "    targets = np.array(dataset.targets)\n",
        "    indices = []\n",
        "    for cls in range(10):\n",
        "        cls_idx = np.where(targets == cls)[0]\n",
        "        indices.extend(np.random.choice(cls_idx, per_class, replace=False))\n",
        "    return indices\n",
        "\n",
        "subset_indices = stratified_random_subset(full_train, per_class=10)\n",
        "small_train = Subset(full_train, subset_indices)\n",
        "print('Subset size:', len(small_train))\n",
        "\n",
        "BATCH_SIZE_SMALL = 32\n",
        "EPOCHS_SMALL = 30  # More epochs because dataset is tiny\n",
        "\n",
        "small_loader = DataLoader(small_train, batch_size=BATCH_SIZE_SMALL, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "model_small = LeNet().to(device)\n",
        "optimizer_small = optim.Adam(model_small.parameters(), lr=1e-3)\n",
        "criterion_small = nn.CrossEntropyLoss()\n",
        "\n",
        "train(model_small, small_loader, criterion_small, optimizer_small, epochs=EPOCHS_SMALL, log_interval=1)\n",
        "acc_small = evaluate(model_small, test_loader)\n",
        "print(f'\\nTest accuracy (random 100 examples): {acc_small:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "968de68d",
      "metadata": {
        "id": "968de68d"
      },
      "source": [
        "## Training on the **distilled synthetic** set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b0da6bfb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0da6bfb",
        "outputId": "e8ba12c7-7716-461f-b09c-4efc2b723e82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic set shape: torch.Size([100, 1, 28, 28])\n",
            "Epoch 1/300 | Batch 1/4 | Loss: 2.2984\rEpoch 1/300 | Batch 2/4 | Loss: 2.2950\rEpoch 1/300 | Batch 3/4 | Loss: 2.3116\rEpoch 1/300 | Batch 4/4 | Loss: 2.3389\rEpoch 1 finished. Avg Loss: 2.3389\n",
            "Epoch 2/300 | Batch 1/4 | Loss: 2.2718\rEpoch 2/300 | Batch 2/4 | Loss: 2.2719\rEpoch 2/300 | Batch 3/4 | Loss: 2.2687\rEpoch 2/300 | Batch 4/4 | Loss: 2.2618\rEpoch 2 finished. Avg Loss: 2.2618\n",
            "Epoch 3/300 | Batch 1/4 | Loss: 2.2553\rEpoch 3/300 | Batch 2/4 | Loss: 2.2457\rEpoch 3/300 | Batch 3/4 | Loss: 2.2464\rEpoch 3/300 | Batch 4/4 | Loss: 2.2229\rEpoch 3 finished. Avg Loss: 2.2229\n",
            "Epoch 4/300 | Batch 1/4 | Loss: 2.2226\rEpoch 4/300 | Batch 2/4 | Loss: 2.2159\rEpoch 4/300 | Batch 3/4 | Loss: 2.1914\rEpoch 4/300 | Batch 4/4 | Loss: 2.1756\rEpoch 4 finished. Avg Loss: 2.1756\n",
            "Epoch 5/300 | Batch 1/4 | Loss: 2.1732\rEpoch 5/300 | Batch 2/4 | Loss: 2.1232\rEpoch 5/300 | Batch 3/4 | Loss: 2.0978\rEpoch 5/300 | Batch 4/4 | Loss: 2.1383\rEpoch 5 finished. Avg Loss: 2.1383\n",
            "Epoch 6/300 | Batch 1/4 | Loss: 2.0181\rEpoch 6/300 | Batch 2/4 | Loss: 1.9888\rEpoch 6/300 | Batch 3/4 | Loss: 1.9809\rEpoch 6/300 | Batch 4/4 | Loss: 2.0018\rEpoch 6 finished. Avg Loss: 2.0018\n",
            "Epoch 7/300 | Batch 1/4 | Loss: 1.9067\rEpoch 7/300 | Batch 2/4 | Loss: 1.8265\rEpoch 7/300 | Batch 3/4 | Loss: 1.8227\rEpoch 7/300 | Batch 4/4 | Loss: 1.8174\rEpoch 7 finished. Avg Loss: 1.8174\n",
            "Epoch 8/300 | Batch 1/4 | Loss: 1.6672\rEpoch 8/300 | Batch 2/4 | Loss: 1.5993\rEpoch 8/300 | Batch 3/4 | Loss: 1.5936\rEpoch 8/300 | Batch 4/4 | Loss: 1.5837\rEpoch 8 finished. Avg Loss: 1.5837\n",
            "Epoch 9/300 | Batch 1/4 | Loss: 1.4513\rEpoch 9/300 | Batch 2/4 | Loss: 1.3992\rEpoch 9/300 | Batch 3/4 | Loss: 1.3414\rEpoch 9/300 | Batch 4/4 | Loss: 1.2059\rEpoch 9 finished. Avg Loss: 1.2059\n",
            "Epoch 10/300 | Batch 1/4 | Loss: 1.0622\rEpoch 10/300 | Batch 2/4 | Loss: 0.9720\rEpoch 10/300 | Batch 3/4 | Loss: 1.0136\rEpoch 10/300 | Batch 4/4 | Loss: 0.9204\rEpoch 10 finished. Avg Loss: 0.9204\n",
            "Epoch 11/300 | Batch 1/4 | Loss: 0.7260\rEpoch 11/300 | Batch 2/4 | Loss: 0.7712\rEpoch 11/300 | Batch 3/4 | Loss: 0.7413\rEpoch 11/300 | Batch 4/4 | Loss: 0.7181\rEpoch 11 finished. Avg Loss: 0.7181\n",
            "Epoch 12/300 | Batch 1/4 | Loss: 0.5007\rEpoch 12/300 | Batch 2/4 | Loss: 0.4715\rEpoch 12/300 | Batch 3/4 | Loss: 0.4633\rEpoch 12/300 | Batch 4/4 | Loss: 0.5227\rEpoch 12 finished. Avg Loss: 0.5227\n",
            "Epoch 13/300 | Batch 1/4 | Loss: 0.4328\rEpoch 13/300 | Batch 2/4 | Loss: 0.3679\rEpoch 13/300 | Batch 3/4 | Loss: 0.3360\rEpoch 13/300 | Batch 4/4 | Loss: 0.2963\rEpoch 13 finished. Avg Loss: 0.2963\n",
            "Epoch 14/300 | Batch 1/4 | Loss: 0.2140\rEpoch 14/300 | Batch 2/4 | Loss: 0.2072\rEpoch 14/300 | Batch 3/4 | Loss: 0.1889\rEpoch 14/300 | Batch 4/4 | Loss: 0.1827\rEpoch 14 finished. Avg Loss: 0.1827\n",
            "Epoch 15/300 | Batch 1/4 | Loss: 0.0800\rEpoch 15/300 | Batch 2/4 | Loss: 0.1057\rEpoch 15/300 | Batch 3/4 | Loss: 0.1501\rEpoch 15/300 | Batch 4/4 | Loss: 0.1325\rEpoch 15 finished. Avg Loss: 0.1325\n",
            "Epoch 16/300 | Batch 1/4 | Loss: 0.0738\rEpoch 16/300 | Batch 2/4 | Loss: 0.0767\rEpoch 16/300 | Batch 3/4 | Loss: 0.0792\rEpoch 16/300 | Batch 4/4 | Loss: 0.0700\rEpoch 16 finished. Avg Loss: 0.0700\n",
            "Epoch 17/300 | Batch 1/4 | Loss: 0.0891\rEpoch 17/300 | Batch 2/4 | Loss: 0.0802\rEpoch 17/300 | Batch 3/4 | Loss: 0.0654\rEpoch 17/300 | Batch 4/4 | Loss: 0.0557\rEpoch 17 finished. Avg Loss: 0.0557\n",
            "Epoch 18 finished. Avg Loss: 0.0308\n",
            "Epoch 19 finished. Avg Loss: 0.0271\n",
            "Epoch 20 finished. Avg Loss: 0.0279\n",
            "Epoch 21 finished. Avg Loss: 0.0165\n",
            "Epoch 22 finished. Avg Loss: 0.0121\n",
            "Epoch 23 finished. Avg Loss: 0.0111\n",
            "Epoch 24 finished. Avg Loss: 0.0073\n",
            "Epoch 25 finished. Avg Loss: 0.0094\n",
            "Epoch 26 finished. Avg Loss: 0.0059\n",
            "Epoch 27 finished. Avg Loss: 0.0154\n",
            "Epoch 28 finished. Avg Loss: 0.0087\n",
            "Epoch 29 finished. Avg Loss: 0.0128\n",
            "Epoch 30 finished. Avg Loss: 0.0033\n",
            "Epoch 31 finished. Avg Loss: 0.0079\n",
            "Epoch 32 finished. Avg Loss: 0.0042\n",
            "Epoch 33 finished. Avg Loss: 0.0029\n",
            "Epoch 34 finished. Avg Loss: 0.0034\n",
            "Epoch 35 finished. Avg Loss: 0.0033\n",
            "Epoch 36 finished. Avg Loss: 0.0036\n",
            "Epoch 37 finished. Avg Loss: 0.0027\n",
            "Epoch 38 finished. Avg Loss: 0.0029\n",
            "Epoch 39 finished. Avg Loss: 0.0027\n",
            "Epoch 40 finished. Avg Loss: 0.0020\n",
            "Epoch 41 finished. Avg Loss: 0.0020\n",
            "Epoch 42 finished. Avg Loss: 0.0019\n",
            "Epoch 43 finished. Avg Loss: 0.0021\n",
            "Epoch 44 finished. Avg Loss: 0.0017\n",
            "Epoch 45 finished. Avg Loss: 0.0014\n",
            "Epoch 46 finished. Avg Loss: 0.0020\n",
            "Epoch 47 finished. Avg Loss: 0.0017\n",
            "Epoch 48 finished. Avg Loss: 0.0020\n",
            "Epoch 49 finished. Avg Loss: 0.0024\n",
            "Epoch 50 finished. Avg Loss: 0.0014\n",
            "Epoch 51 finished. Avg Loss: 0.0014\n",
            "Epoch 52 finished. Avg Loss: 0.0011\n",
            "Epoch 53 finished. Avg Loss: 0.0018\n",
            "Epoch 54 finished. Avg Loss: 0.0010\n",
            "Epoch 55 finished. Avg Loss: 0.0012\n",
            "Epoch 56 finished. Avg Loss: 0.0011\n",
            "Epoch 57 finished. Avg Loss: 0.0013\n",
            "Epoch 58 finished. Avg Loss: 0.0013\n",
            "Epoch 59 finished. Avg Loss: 0.0010\n",
            "Epoch 60 finished. Avg Loss: 0.0009\n",
            "Epoch 61 finished. Avg Loss: 0.0009\n",
            "Epoch 62 finished. Avg Loss: 0.0008\n",
            "Epoch 63 finished. Avg Loss: 0.0011\n",
            "Epoch 64 finished. Avg Loss: 0.0009\n",
            "Epoch 65 finished. Avg Loss: 0.0011\n",
            "Epoch 66 finished. Avg Loss: 0.0010\n",
            "Epoch 67 finished. Avg Loss: 0.0009\n",
            "Epoch 68 finished. Avg Loss: 0.0007\n",
            "Epoch 69 finished. Avg Loss: 0.0008\n",
            "Epoch 70 finished. Avg Loss: 0.0008\n",
            "Epoch 71 finished. Avg Loss: 0.0011\n",
            "Epoch 72 finished. Avg Loss: 0.0007\n",
            "Epoch 73 finished. Avg Loss: 0.0010\n",
            "Epoch 74 finished. Avg Loss: 0.0006\n",
            "Epoch 75 finished. Avg Loss: 0.0007\n",
            "Epoch 76 finished. Avg Loss: 0.0010\n",
            "Epoch 77 finished. Avg Loss: 0.0005\n",
            "Epoch 78 finished. Avg Loss: 0.0006\n",
            "Epoch 79 finished. Avg Loss: 0.0007\n",
            "Epoch 80 finished. Avg Loss: 0.0007\n",
            "Epoch 81 finished. Avg Loss: 0.0006\n",
            "Epoch 82 finished. Avg Loss: 0.0005\n",
            "Epoch 83 finished. Avg Loss: 0.0008\n",
            "Epoch 84 finished. Avg Loss: 0.0005\n",
            "Epoch 85 finished. Avg Loss: 0.0005\n",
            "Epoch 86 finished. Avg Loss: 0.0006\n",
            "Epoch 87 finished. Avg Loss: 0.0007\n",
            "Epoch 88 finished. Avg Loss: 0.0004\n",
            "Epoch 89 finished. Avg Loss: 0.0005\n",
            "Epoch 90 finished. Avg Loss: 0.0005\n",
            "Epoch 91 finished. Avg Loss: 0.0008\n",
            "Epoch 92 finished. Avg Loss: 0.0005\n",
            "Epoch 93 finished. Avg Loss: 0.0005\n",
            "Epoch 94 finished. Avg Loss: 0.0005\n",
            "Epoch 95 finished. Avg Loss: 0.0004\n",
            "Epoch 96 finished. Avg Loss: 0.0004\n",
            "Epoch 97 finished. Avg Loss: 0.0006\n",
            "Epoch 98 finished. Avg Loss: 0.0004\n",
            "Epoch 99 finished. Avg Loss: 0.0004\n",
            "Epoch 100 finished. Avg Loss: 0.0004\n",
            "Epoch 101 finished. Avg Loss: 0.0004\n",
            "Epoch 102 finished. Avg Loss: 0.0005\n",
            "Epoch 103 finished. Avg Loss: 0.0004\n",
            "Epoch 104 finished. Avg Loss: 0.0003\n",
            "Epoch 105 finished. Avg Loss: 0.0004\n",
            "Epoch 106 finished. Avg Loss: 0.0004\n",
            "Epoch 107 finished. Avg Loss: 0.0003\n",
            "Epoch 108 finished. Avg Loss: 0.0003\n",
            "Epoch 109 finished. Avg Loss: 0.0003\n",
            "Epoch 110 finished. Avg Loss: 0.0004\n",
            "Epoch 111 finished. Avg Loss: 0.0003\n",
            "Epoch 112 finished. Avg Loss: 0.0004\n",
            "Epoch 113 finished. Avg Loss: 0.0003\n",
            "Epoch 114 finished. Avg Loss: 0.0003\n",
            "Epoch 115 finished. Avg Loss: 0.0003\n",
            "Epoch 116 finished. Avg Loss: 0.0003\n",
            "Epoch 117 finished. Avg Loss: 0.0003\n",
            "Epoch 118 finished. Avg Loss: 0.0003\n",
            "Epoch 119 finished. Avg Loss: 0.0003\n",
            "Epoch 120 finished. Avg Loss: 0.0003\n",
            "Epoch 121 finished. Avg Loss: 0.0003\n",
            "Epoch 122 finished. Avg Loss: 0.0004\n",
            "Epoch 123 finished. Avg Loss: 0.0003\n",
            "Epoch 124 finished. Avg Loss: 0.0002\n",
            "Epoch 125 finished. Avg Loss: 0.0004\n",
            "Epoch 126 finished. Avg Loss: 0.0003\n",
            "Epoch 127 finished. Avg Loss: 0.0003\n",
            "Epoch 128 finished. Avg Loss: 0.0003\n",
            "Epoch 129 finished. Avg Loss: 0.0003\n",
            "Epoch 130 finished. Avg Loss: 0.0003\n",
            "Epoch 131 finished. Avg Loss: 0.0002\n",
            "Epoch 132 finished. Avg Loss: 0.0002\n",
            "Epoch 133 finished. Avg Loss: 0.0002\n",
            "Epoch 134 finished. Avg Loss: 0.0002\n",
            "Epoch 135 finished. Avg Loss: 0.0003\n",
            "Epoch 136 finished. Avg Loss: 0.0002\n",
            "Epoch 137 finished. Avg Loss: 0.0003\n",
            "Epoch 138 finished. Avg Loss: 0.0002\n",
            "Epoch 139 finished. Avg Loss: 0.0003\n",
            "Epoch 140 finished. Avg Loss: 0.0003\n",
            "Epoch 141 finished. Avg Loss: 0.0002\n",
            "Epoch 142 finished. Avg Loss: 0.0003\n",
            "Epoch 143 finished. Avg Loss: 0.0002\n",
            "Epoch 144 finished. Avg Loss: 0.0002\n",
            "Epoch 145 finished. Avg Loss: 0.0002\n",
            "Epoch 146 finished. Avg Loss: 0.0002\n",
            "Epoch 147 finished. Avg Loss: 0.0002\n",
            "Epoch 148 finished. Avg Loss: 0.0002\n",
            "Epoch 149 finished. Avg Loss: 0.0002\n",
            "Epoch 150 finished. Avg Loss: 0.0002\n",
            "Epoch 151 finished. Avg Loss: 0.0002\n",
            "Epoch 152 finished. Avg Loss: 0.0002\n",
            "Epoch 153 finished. Avg Loss: 0.0002\n",
            "Epoch 154 finished. Avg Loss: 0.0002\n",
            "Epoch 155 finished. Avg Loss: 0.0002\n",
            "Epoch 156 finished. Avg Loss: 0.0002\n",
            "Epoch 157 finished. Avg Loss: 0.0002\n",
            "Epoch 158 finished. Avg Loss: 0.0001\n",
            "Epoch 159 finished. Avg Loss: 0.0002\n",
            "Epoch 160 finished. Avg Loss: 0.0002\n",
            "Epoch 161 finished. Avg Loss: 0.0002\n",
            "Epoch 162 finished. Avg Loss: 0.0001\n",
            "Epoch 163 finished. Avg Loss: 0.0002\n",
            "Epoch 164 finished. Avg Loss: 0.0002\n",
            "Epoch 165 finished. Avg Loss: 0.0002\n",
            "Epoch 166 finished. Avg Loss: 0.0002\n",
            "Epoch 167 finished. Avg Loss: 0.0001\n",
            "Epoch 168 finished. Avg Loss: 0.0002\n",
            "Epoch 169 finished. Avg Loss: 0.0001\n",
            "Epoch 170 finished. Avg Loss: 0.0002\n",
            "Epoch 171 finished. Avg Loss: 0.0001\n",
            "Epoch 172 finished. Avg Loss: 0.0002\n",
            "Epoch 173 finished. Avg Loss: 0.0002\n",
            "Epoch 174 finished. Avg Loss: 0.0001\n",
            "Epoch 175 finished. Avg Loss: 0.0001\n",
            "Epoch 176 finished. Avg Loss: 0.0001\n",
            "Epoch 177 finished. Avg Loss: 0.0002\n",
            "Epoch 178 finished. Avg Loss: 0.0001\n",
            "Epoch 179 finished. Avg Loss: 0.0002\n",
            "Epoch 180 finished. Avg Loss: 0.0002\n",
            "Epoch 181 finished. Avg Loss: 0.0002\n",
            "Epoch 182 finished. Avg Loss: 0.0001\n",
            "Epoch 183 finished. Avg Loss: 0.0001\n",
            "Epoch 184 finished. Avg Loss: 0.0001\n",
            "Epoch 185 finished. Avg Loss: 0.0002\n",
            "Epoch 186 finished. Avg Loss: 0.0001\n",
            "Epoch 187 finished. Avg Loss: 0.0002\n",
            "Epoch 188 finished. Avg Loss: 0.0001\n",
            "Epoch 189 finished. Avg Loss: 0.0001\n",
            "Epoch 190 finished. Avg Loss: 0.0002\n",
            "Epoch 191 finished. Avg Loss: 0.0001\n",
            "Epoch 192 finished. Avg Loss: 0.0001\n",
            "Epoch 193 finished. Avg Loss: 0.0001\n",
            "Epoch 194 finished. Avg Loss: 0.0001\n",
            "Epoch 195 finished. Avg Loss: 0.0001\n",
            "Epoch 196 finished. Avg Loss: 0.0001\n",
            "Epoch 197 finished. Avg Loss: 0.0001\n",
            "Epoch 198 finished. Avg Loss: 0.0001\n",
            "Epoch 199 finished. Avg Loss: 0.0001\n",
            "Epoch 200 finished. Avg Loss: 0.0001\n",
            "Epoch 201 finished. Avg Loss: 0.0001\n",
            "Epoch 202 finished. Avg Loss: 0.0001\n",
            "Epoch 203 finished. Avg Loss: 0.0001\n",
            "Epoch 204 finished. Avg Loss: 0.0001\n",
            "Epoch 205 finished. Avg Loss: 0.0001\n",
            "Epoch 206 finished. Avg Loss: 0.0001\n",
            "Epoch 207 finished. Avg Loss: 0.0001\n",
            "Epoch 208 finished. Avg Loss: 0.0001\n",
            "Epoch 209 finished. Avg Loss: 0.0001\n",
            "Epoch 210 finished. Avg Loss: 0.0001\n",
            "Epoch 211 finished. Avg Loss: 0.0001\n",
            "Epoch 212 finished. Avg Loss: 0.0001\n",
            "Epoch 213 finished. Avg Loss: 0.0001\n",
            "Epoch 214 finished. Avg Loss: 0.0001\n",
            "Epoch 215 finished. Avg Loss: 0.0001\n",
            "Epoch 216 finished. Avg Loss: 0.0001\n",
            "Epoch 217 finished. Avg Loss: 0.0001\n",
            "Epoch 218 finished. Avg Loss: 0.0001\n",
            "Epoch 219 finished. Avg Loss: 0.0001\n",
            "Epoch 220 finished. Avg Loss: 0.0001\n",
            "Epoch 221 finished. Avg Loss: 0.0001\n",
            "Epoch 222 finished. Avg Loss: 0.0001\n",
            "Epoch 223 finished. Avg Loss: 0.0001\n",
            "Epoch 224 finished. Avg Loss: 0.0001\n",
            "Epoch 225 finished. Avg Loss: 0.0001\n",
            "Epoch 226 finished. Avg Loss: 0.0001\n",
            "Epoch 227 finished. Avg Loss: 0.0001\n",
            "Epoch 228 finished. Avg Loss: 0.0001\n",
            "Epoch 229 finished. Avg Loss: 0.0001\n",
            "Epoch 230 finished. Avg Loss: 0.0001\n",
            "Epoch 231 finished. Avg Loss: 0.0001\n",
            "Epoch 232 finished. Avg Loss: 0.0001\n",
            "Epoch 233 finished. Avg Loss: 0.0001\n",
            "Epoch 234 finished. Avg Loss: 0.0001\n",
            "Epoch 235 finished. Avg Loss: 0.0001\n",
            "Epoch 236 finished. Avg Loss: 0.0001\n",
            "Epoch 237 finished. Avg Loss: 0.0001\n",
            "Epoch 238 finished. Avg Loss: 0.0001\n",
            "Epoch 239 finished. Avg Loss: 0.0001\n",
            "Epoch 240 finished. Avg Loss: 0.0001\n",
            "Epoch 241 finished. Avg Loss: 0.0001\n",
            "Epoch 242 finished. Avg Loss: 0.0001\n",
            "Epoch 243 finished. Avg Loss: 0.0001\n",
            "Epoch 244 finished. Avg Loss: 0.0001\n",
            "Epoch 245 finished. Avg Loss: 0.0001\n",
            "Epoch 246 finished. Avg Loss: 0.0001\n",
            "Epoch 247 finished. Avg Loss: 0.0001\n",
            "Epoch 248 finished. Avg Loss: 0.0001\n",
            "Epoch 249 finished. Avg Loss: 0.0001\n",
            "Epoch 250 finished. Avg Loss: 0.0001\n",
            "Epoch 251 finished. Avg Loss: 0.0001\n",
            "Epoch 252 finished. Avg Loss: 0.0001\n",
            "Epoch 253 finished. Avg Loss: 0.0001\n",
            "Epoch 254 finished. Avg Loss: 0.0001\n",
            "Epoch 255 finished. Avg Loss: 0.0001\n",
            "Epoch 256 finished. Avg Loss: 0.0001\n",
            "Epoch 257 finished. Avg Loss: 0.0001\n",
            "Epoch 258 finished. Avg Loss: 0.0001\n",
            "Epoch 259 finished. Avg Loss: 0.0001\n",
            "Epoch 260 finished. Avg Loss: 0.0001\n",
            "Epoch 261 finished. Avg Loss: 0.0001\n",
            "Epoch 262 finished. Avg Loss: 0.0001\n",
            "Epoch 263 finished. Avg Loss: 0.0001\n",
            "Epoch 264 finished. Avg Loss: 0.0001\n",
            "Epoch 265 finished. Avg Loss: 0.0001\n",
            "Epoch 266 finished. Avg Loss: 0.0001\n",
            "Epoch 267 finished. Avg Loss: 0.0001\n",
            "Epoch 268 finished. Avg Loss: 0.0001\n",
            "Epoch 269 finished. Avg Loss: 0.0001\n",
            "Epoch 270 finished. Avg Loss: 0.0001\n",
            "Epoch 271 finished. Avg Loss: 0.0001\n",
            "Epoch 272 finished. Avg Loss: 0.0001\n",
            "Epoch 273 finished. Avg Loss: 0.0001\n",
            "Epoch 274 finished. Avg Loss: 0.0000\n",
            "Epoch 275 finished. Avg Loss: 0.0001\n",
            "Epoch 276 finished. Avg Loss: 0.0001\n",
            "Epoch 277 finished. Avg Loss: 0.0000\n",
            "Epoch 278 finished. Avg Loss: 0.0001\n",
            "Epoch 279 finished. Avg Loss: 0.0001\n",
            "Epoch 280 finished. Avg Loss: 0.0001\n",
            "Epoch 281 finished. Avg Loss: 0.0001\n",
            "Epoch 282 finished. Avg Loss: 0.0001\n",
            "Epoch 283 finished. Avg Loss: 0.0001\n",
            "Epoch 284 finished. Avg Loss: 0.0001\n",
            "Epoch 285 finished. Avg Loss: 0.0000\n",
            "Epoch 286 finished. Avg Loss: 0.0001\n",
            "Epoch 287 finished. Avg Loss: 0.0000\n",
            "Epoch 288 finished. Avg Loss: 0.0001\n",
            "Epoch 289 finished. Avg Loss: 0.0000\n",
            "Epoch 290 finished. Avg Loss: 0.0001\n",
            "Epoch 291 finished. Avg Loss: 0.0001\n",
            "Epoch 292 finished. Avg Loss: 0.0001\n",
            "Epoch 293 finished. Avg Loss: 0.0001\n",
            "Epoch 294 finished. Avg Loss: 0.0001\n",
            "Epoch 295 finished. Avg Loss: 0.0001\n",
            "Epoch 296 finished. Avg Loss: 0.0000\n",
            "Epoch 297 finished. Avg Loss: 0.0001\n",
            "Epoch 298 finished. Avg Loss: 0.0000\n",
            "Epoch 299 finished. Avg Loss: 0.0001\n",
            "Epoch 300 finished. Avg Loss: 0.0000\n",
            "\n",
            "Test accuracy (distilled set): 81.91%\n"
          ]
        }
      ],
      "source": [
        "SYNSET_PATH = 'distiller/syndata/MNIST_LeNet_ipc-10_exp-0.pt'\n",
        "\n",
        "assert Path(SYNSET_PATH).exists(), (\n",
        "    f'Distilled file not found at {SYNSET_PATH}. ' \\\n",
        "    'Upload it to the Colab session or place it in the working directory.'\n",
        ")\n",
        "\n",
        "checkpoint = torch.load(SYNSET_PATH, map_location='cpu')\n",
        "\n",
        "# Expected keys: images (n, 1, 28, 28) tensor, labels (n) tensor\n",
        "synthetic_images = checkpoint.get('syn_imgs') if isinstance(checkpoint, dict) else checkpoint[0]\n",
        "synthetic_labels = checkpoint.get('syn_labels') if isinstance(checkpoint, dict) else checkpoint[1]\n",
        "\n",
        "print('Synthetic set shape:', synthetic_images.shape)\n",
        "\n",
        "distill_ds = TensorDataset(synthetic_images, synthetic_labels)\n",
        "BATCH_SIZE_DISTILL = 32\n",
        "EPOCHS_DISTILL = 300\n",
        "\n",
        "distill_loader = DataLoader(distill_ds, batch_size=BATCH_SIZE_DISTILL, shuffle=True)\n",
        "\n",
        "model_distill = LeNet().to(device)\n",
        "optimizer_distill = optim.Adam(model_distill.parameters(), lr=1e-3)\n",
        "criterion_distill = nn.CrossEntropyLoss()\n",
        "\n",
        "train(model_distill, distill_loader, criterion_distill, optimizer_distill, epochs=EPOCHS_DISTILL, log_interval=1)\n",
        "acc_distill = evaluate(model_distill, test_loader)\n",
        "print(f'\\nTest accuracy (distilled set): {acc_distill:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f7a3645",
      "metadata": {
        "id": "3f7a3645"
      },
      "source": [
        "## Result Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "fb2ffd46",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "fb2ffd46",
        "outputId": "fcb1943b-4eae-4b18-b1a2-63e727cdb1b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Data   : 97.00%\n",
            "Random 100  : 78.31%\n",
            "Distilled Set: 81.91%\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhwAAAF2CAYAAAAleUHdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUVZJREFUeJzt3XdYFFfbBvB7QZogSC+KgGJBo6hYY0EFxUZsETVGsRNjN9EEG3bs3agYRZNYscUSsWDBihXF3lBsoAYpoiKw5/vDj3ldFxR0R0ru33XtpXPmzJlndmeHZ8+cmVEIIQSIiIiIZKSV1wEQERFR4ceEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDCowXL16gT58+sLGxgUKhwNChQ/M6JCrgxo8fD4VCkddhEP0nMOH4QlatWgWFQoEzZ858dlt3796FQqGAQqHA5s2b1eZnHkSfPXuW67aPHz+O8ePHIyEhIUf1e/ToIcWiUChgbGwMV1dXzJ49G6mpqble/4dMnToVq1atQv/+/fHnn3+iW7duGm3/vygjIwPBwcFo1KgRzMzMoKenB0dHR/Ts2VMj+yrlf5nHJoVCgaNHj6rNF0LA3t4eCoUCrVu3VpmXudzs2bOzbffd/Si7Y9OOHTvg7u4OKysrFC1aFKVLl4aPjw9CQ0MBAI0aNVI5zmT3Gj9+vFochw4dytGymko8r1y5gvHjx+Pu3bs5Xubo0aNo0aIFSpQoAX19fZQqVQre3t5Yu3btJ8Xw22+/YdWqVZ+0rJyK5HUA9HkmTpyI9u3ba+zLcvz4cUyYMAE9evRA8eLFc7SMnp4efv/9dwBAQkICNm/ejJ9//hmnT5/G+vXrNRIXABw4cAB16tRBQECAxtr8L3v16hXat2+P0NBQNGzYEKNGjYKZmRnu3r2LjRs3YvXq1YiJiUHJkiXzOlTZjBkzBr/++mteh5Ev6OvrY+3atahfv75K+eHDh/HgwQPo6ellu+zMmTPRv39/FC1aNNfrnTVrFkaMGAF3d3f4+/ujaNGiuHXrFvbv34/169ejefPmGD16NPr06SMtc/r0aSxYsACjRo2Ci4uLVF6lShW19l1cXPDnn3+qlPn7+8PIyAijR4/Odbwfc+XKFUyYMAGNGjWCo6PjR+uHhISgU6dOqFq1KoYMGQJTU1NER0cjPDwcy5cvx3fffZfrGH777TdYWFigR48eud8AGTHhKMCqVq2KyMhIbN26Fe3bt8+zOIoUKYLvv/9emv7xxx9Ru3ZtbNiwAXPmzIGdnd0nt61UKvHmzRvo6+vjyZMnqFixoiZCBgCkp6dDqVRCV1dXY20WJCNGjEBoaCjmzp2rdnoqICAAc+fOzZvAvoCUlBQYGhqiSJEiKFKEh0EAaNmyJUJCQrBgwQKV92Tt2rVwc3PLtsc08zi0dOlSDB8+PFfrTE9Px6RJk9C0aVPs3btXbf6TJ08AAE2bNlUp19fXx4IFC9C0aVM0atTog+uwtrZWOT4BwLRp02BhYaFWnhfGjx+PihUr4uTJk2rHosztLyx4SiWfefjwIXr16gVra2vo6emhUqVKWLlyZZZ1O3fujHLlymHixInIyUN/IyIi0Lx5c5iYmKBo0aJwd3fHsWPHpPnjx4/HiBEjAABOTk5SN2NuugYBQEtLSzoIZC6bmpqKgIAAODs7Q09PD/b29hg5cqTaaReFQoGBAwdizZo1qFSpEvT09BAaGgqFQoHo6Gjs2rVLLa4nT56gd+/esLa2hr6+PlxdXbF69WqVdjNPQ82aNQvz5s1DmTJloKenJ3V/KhQK3LhxA99//z1MTExgaWmJsWPHQgiB+/fvo02bNjA2NoaNjY1a9/GbN28wbtw4uLm5wcTEBIaGhmjQoAEOHjyYbQxBQUFSDDVr1sTp06fV3sdr167Bx8cHlpaWMDAwQPny5dV+keVmf3nXgwcPsGzZMjRt2jTLsTDa2tr4+eefVXo3zp8/jxYtWsDY2BhGRkbw8PDAyZMnVZbL7EY/evQoBg8eDEtLSxQvXhx+fn548+YNEhIS0L17d5iamsLU1BQjR45U2XfffY/mzp0LBwcHGBgYwN3dHZcuXVJZ18WLF9GjRw+ULl0a+vr6sLGxQa9evfDvv/+q1Mv8fK9cuYLvvvsOpqam0q/4rMZw7Nu3D/Xr10fx4sVhZGSE8uXLY9SoUSp1crvP5eTzzsqdO3fQsWNHmJmZoWjRoqhTpw527dqlUifzlMHGjRsxZcoUlCxZEvr6+vDw8MCtW7dytB4A6NKlC/7991/s27dPKnvz5g02bdr0wV/Z9erVQ5MmTTBjxgy8evUqx+sDgGfPniEpKQn16tXLcr6VlVWu2vscCQkJGDp0KOzt7aGnpwdnZ2dMnz4dSqVSpd769evh5uaGYsWKwdjYGJUrV8b8+fMBvN3/O3bsCABo3LixdKw6dOhQtuu9ffs2atasmeUPn/e3X6lUYt68eahUqRL09fVhbW0NPz8/PH/+XKrj6OiIy5cv4/Dhw9L6P5aUfSlM7fORuLg41KlTR/qja2lpid27d6N3795ISkpS+8Ogra2NMWPGoHv37h/t5Thw4ABatGgBNzc3BAQEQEtLC8HBwWjSpAmOHDmCWrVqoX379rhx4wbWrVuHuXPnwsLCAgBgaWmZ6225ffs2AMDc3BxKpRLffPMNjh49in79+sHFxQVRUVGYO3cubty4gW3btqnFunHjRgwcOBAWFhawtbXFn3/+iWHDhqFkyZL46aefpLhevXqFRo0a4datWxg4cCCcnJwQEhKCHj16ICEhAUOGDFFpOzg4GK9fv0a/fv2gp6cHMzMzaV6nTp3g4uKCadOmYdeuXZg8eTLMzMywbNkyNGnSBNOnT8eaNWvw888/o2bNmmjYsCEAICkpCb///ju6dOmCvn37Ijk5GStWrICXlxdOnTqFqlWrqsSwdu1aJCcnw8/PDwqFAjNmzED79u1x584d6OjoAHj7x7RBgwbQ0dFBv3794OjoiNu3b2PHjh2YMmUKgNzvL+/avXs30tPTczwO5vLly2jQoAGMjY0xcuRI6OjoYNmyZWjUqBEOHz6M2rVrq9QfNGgQbGxsMGHCBJw8eRJBQUEoXrw4jh8/jlKlSmHq1Kn4559/MHPmTHz11Vfo3r27yvJ//PEHkpOTMWDAALx+/Rrz589HkyZNEBUVBWtrawBvE4M7d+6gZ8+esLGxweXLlxEUFITLly/j5MmTaolEx44dUbZsWUydOjXbBP3y5cto3bo1qlSpgokTJ0JPTw+3bt1SScxzu8/l5PPOSlxcHL7++mu8fPkSgwcPhrm5OVavXo1vvvkGmzZtQrt27VTqT5s2DVpaWvj555+RmJiIGTNmoGvXroiIiMh2He9ydHRE3bp1sW7dOrRo0QLA2/0kMTERnTt3xoIFC7Jddvz48WjYsCGWLFmSq14OKysrGBgYYMeOHRg0aJDK9/FLevnyJdzd3fHw4UP4+fmhVKlSOH78OPz9/fH48WPMmzcPwNt9rkuXLvDw8MD06dMBAFevXsWxY8cwZMgQNGzYEIMHD1Y73fPuaZ/3OTg4ICwsDA8ePPjo6Us/Pz+sWrUKPXv2xODBgxEdHY1Fixbh/PnzOHbsGHR0dDBv3jwMGjRI5ZRR5ncmzwn6IoKDgwUAcfr06Wzr9O7dW9ja2opnz56plHfu3FmYmJiIly9fCiGEiI6OFgDEzJkzRXp6uihbtqxwdXUVSqVSCCFEQECAACCePn0qhBBCqVSKsmXLCi8vL6mOEEK8fPlSODk5iaZNm0plM2fOFABEdHR0jrbL19dXGBoaiqdPn4qnT5+KW7duialTpwqFQiGqVKkihBDizz//FFpaWuLIkSMqyy5dulQAEMeOHZPKAAgtLS1x+fJltXU5ODiIVq1aqZTNmzdPABB//fWXVPbmzRtRt25dYWRkJJKSklTeM2NjY/HkyROVNjLfr379+kll6enpomTJkkKhUIhp06ZJ5c+fPxcGBgbC19dXpW5qaqpKm8+fPxfW1taiV69eUllmDObm5iI+Pl4q//vvvwUAsWPHDqmsYcOGolixYuLevXsq7b77+eV0f8nKsGHDBABx/vz5bOu8q23btkJXV1fcvn1bKnv06JEoVqyYaNiwoVSWuZ+/v6/VrVtXKBQK8cMPP0hlme+xu7u7VJb5HhkYGIgHDx5I5REREQKAGDZsmFSW1fatW7dOABDh4eFSWebn26VLF7X6mfMyzZ07V+W7k5Xc7nM5+byzMnToUAFA5XuTnJwsnJychKOjo8jIyBBCCHHw4EEBQLi4uKjsh/PnzxcARFRU1AfX8+6xadGiRaJYsWLSe9uxY0fRuHFjIUTW3z8AYsCAAUIIIRo3bixsbGykZbM65r1/bBJCiHHjxgkAwtDQULRo0UJMmTJFnD179oMxh4SECADi4MGDH6yXnUqVKqnsd5MmTRKGhobixo0bKvV+/fVXoa2tLWJiYoQQQgwZMkQYGxuL9PR0jcW2YsUKAUDo6uqKxo0bi7Fjx4ojR45In2+mI0eOCABizZo1KuWhoaFq5e9vX37BUyr5hBACmzdvhre3N4QQePbsmfTy8vJCYmIizp07p7ZcZi/HhQsX1HoKMkVGRuLmzZv47rvv8O+//0rtpqSkwMPDA+Hh4WrdhrmRkpICS0tLWFpawtnZGaNGjULdunWxdetWAG8HRbm4uKBChQoq29WkSRMAUDv14O7unuOxGv/88w9sbGzQpUsXqUxHRweDBw/GixcvcPjwYZX6HTp0yLbH5t1Badra2qhRowaEEOjdu7dUXrx4cZQvXx537txRqZvZHapUKhEfH4/09HTUqFEjy8+sU6dOMDU1laYbNGgAAFKbT58+RXh4OHr16oVSpUqpLJv5q/1T95dMSUlJAIBixYplWydTRkYG9u7di7Zt26J06dJSua2tLb777jscPXpUai9T7969VXoYateurfZeZr7H776Xmdq2bYsSJUpI07Vq1ULt2rXxzz//SGUGBgbS/1+/fo1nz56hTp06AJDltv/www8f3dbMgdJ///13tt+J3O5zH/u8s/PPP/+gVq1aKoM4jYyM0K9fP9y9exdXrlxRqd+zZ0+VbvmcruddPj4+ePXqFXbu3Ink5GTs3Lkzx4MWx48fj9jYWCxdujTH6wOACRMmYO3atahWrRr27NmD0aNHw83NDdWrV8fVq1dz1danCgkJQYMGDWBqaqryXfL09ERGRgbCw8MBvN0/UlJSVE47fa5evXohNDQUjRo1wtGjRzFp0iQ0aNAAZcuWxfHjx1ViNDExQdOmTVVidHNzg5GRkdpxND9iwpFPPH36FAkJCQgKCpL+eGe+evbsCSD7AURdu3aFs7NztmM5bt68CQDw9fVVa/v3339HamoqEhMTPzl2fX197Nu3D/v27UN4eDju37+PY8eOSX+cbt68icuXL6utu1y5cllul5OTU47Xfe/ePZQtWxZaWqq7cmYX5r1793Lc9vt/3E1MTKCvry+dWnq3/N1zpgCwevVqVKlSBfr6+jA3N4elpSV27dqV5fv6/noy/xhltpn5B+Krr77KNtbP2V8AwNjYGACQnJycbZ131/Xy5UuUL19ebZ6LiwuUSiXu37+vUp7VewkA9vb2auXvv5cAULZsWbWycuXKqYwnio+Px5AhQ2BtbQ0DAwNYWlpKn29W73tO9qtOnTqhXr166NOnD6ytrdG5c2ds3LhRJfnI7T73sc87O/fu3cv2Pdfket5laWkJT09PrF27Flu2bEFGRga+/fbbHC3bsGFDNG7c+JPGcnTp0gVHjhzB8+fPsXfvXnz33Xc4f/48vL298fr161y19Slu3ryJ0NBQte+Sp6cngP99l3788UeUK1cOLVq0QMmSJaVk4XN5eXlhz549SEhIQHh4OAYMGIB79+6hdevW0rpv3ryJxMREWFlZqcX54sWLAjHAlGM48onMA9r3338PX1/fLOtkdckX8L9ejh49euDvv//Otu2ZM2eqjSfIZGRk9AlR/2/9mV/MrCiVSlSuXBlz5szJcv77f4Te/eWqaR9qW1tbO0dlAFQSu7/++gs9evRA27ZtMWLECFhZWUFbWxuBgYHSWJbctvkxn7O/AECFChUAAFFRUdnuE58ju23Mqjw32/0uHx8fHD9+HCNGjEDVqlVhZGQEpVKJ5s2bZ9k7kZP9ysDAAOHh4Th48CB27dqF0NBQbNiwAU2aNMHevXuz3a4P0cTn/SXX891336Fv376IjY1FixYtcnx5PPD26qZGjRph2bJluVouk7GxMZo2bYqmTZtCR0cHq1evRkREBNzd3XPdVm4olUo0bdoUI0eOzHJ+5o8jKysrREZGYs+ePdi9ezd2796N4OBgdO/eXW3Q8KcoWrQoGjRogAYNGsDCwgITJkzA7t274evrC6VSCSsrK6xZsybLZT9lrN2XxoQjn7C0tESxYsWQkZHxwT/e2fn+++8xefJkTJgwAd98843KvDJlygB4+2X+WNty3HWxTJkyuHDhAjw8PDTevoODAy5evAilUqnyi/PatWvSfLlt2rQJpUuXxpYtW1S271PvF5LZM/T+VRnv+tz9pUWLFtDW1sZff/310YGjlpaWKFq0KK5fv64279q1a9DS0lJLGj9XZq/cu27cuCHd1+D58+cICwvDhAkTMG7cuA8ul1taWlrw8PCAh4cH5syZg6lTp2L06NE4ePAgPD09v9g+5+DgkO17rsn1vK9du3bw8/PDyZMnsWHDhlwt6+7ujkaNGmH69Okqn8unqFGjBlavXo3Hjx9/Vjs5UaZMGbx48SJH3yVdXV14e3vD29sbSqUSP/74I5YtW4axY8fC2dlZY8e4GjVqAIC0/WXKlMH+/ftRr169jybP+fXuuTylkk9oa2ujQ4cO2Lx5c5Z/aJ4+ffrR5ceMGYPIyEhs375dZZ6bmxvKlCmDWbNm4cWLFx9s29DQEAByfKfRnPDx8cHDhw+xfPlytXmvXr1CSkrKJ7fdsmVLxMbGqhwY09PTsXDhQhgZGcn+ywj43y/Ld39JRkRE4MSJE5/UnqWlJRo2bIiVK1ciJiZGZV7mOj53f7G3t0ffvn2xd+9eLFy4UG2+UqnE7Nmz8eDBA2hra6NZs2b4+++/VU5pxMXFSTeKyjxFoynbtm3Dw4cPpelTp04hIiJCunoiq/ccgHQ1waeKj49XK8vsAcq8hPtL7XMtW7bEqVOnVPajlJQUBAUFwdHRUaP3pHmXkZERlixZgvHjx8Pb2zvXy2eO5QgKCvpo3ZcvX2b7Pdm9ezcAZHlaSdN8fHxw4sQJ7NmzR21eQkIC0tPTAUDtkmstLS2pJzFz/8jtMTQsLCzL8szxSpnb7+Pjg4yMDEyaNEmtbnp6usr6DA0NNXoM1xT2cHxhK1euzPKc35AhQzBt2jQcPHgQtWvXRt++fVGxYkXEx8fj3Llz2L9/f5YHw3d17doVkyZNQmRkpEq5lpYWfv/9d7Ro0QKVKlVCz549UaJECTx8+BAHDx6EsbExduzYAeBtcgIAo0ePRufOnaGjowNvb2/pS/QpunXrho0bN+KHH37AwYMHUa9ePWRkZODatWvYuHEj9uzZI2XzudWvXz8sW7YMPXr0wNmzZ+Ho6IhNmzbh2LFjmDdvXo4GRX6u1q1bY8uWLWjXrh1atWqF6OhoLF26FBUrVswywcuJBQsWoH79+qhevTr69esHJycn3L17F7t27ZI+38/dX2bPno3bt29j8ODB2LJlC1q3bg1TU1PExMQgJCQE165dQ+fOnQEAkydPlu5P8eOPP6JIkSJYtmwZUlNTMWPGjE/axg9xdnZG/fr10b9/f6SmpmLevHkwNzeXuryNjY3RsGFDzJgxA2lpaShRogT27t2L6Ojoz1rvxIkTER4ejlatWsHBwQFPnjzBb7/9hpIlS0qDN7/UPvfrr79Kl6gOHjwYZmZmWL16NaKjo7F582a1MSSalN1pupxwd3eHu7u72uDZrLx8+RJff/016tSpg+bNm8Pe3h4JCQnYtm0bjhw5grZt26JatWqfHEtOjRgxAtu3b0fr1q3Ro0cPuLm5ISUlBVFRUdi0aRPu3r0LCwsL9OnTB/Hx8WjSpAlKliyJe/fuYeHChahatao0tqZq1arQ1tbG9OnTkZiYCD09PTRp0iTbe4q0adMGTk5O8Pb2RpkyZZCSkoL9+/djx44dqFmzppT0ubu7w8/PD4GBgYiMjESzZs2go6ODmzdvIiQkBPPnz5fG27i5uWHJkiWYPHkynJ2dYWVlJQ3Sz1N5cGXMf1LmJWLZve7fvy+EECIuLk4MGDBA2NvbCx0dHWFjYyM8PDxEUFCQ1Na7l8V+aD3vX9p3/vx50b59e2Fubi709PSEg4OD8PHxEWFhYSr1Jk2aJEqUKCG0tLQ+eols5mWxH/PmzRsxffp0UalSJaGnpydMTU2Fm5ubmDBhgkhMTJTq4Z3L7N6X1WV5Qrx9z3r27CksLCyErq6uqFy5sggODlap86H3LKtL9T60be7u7qJSpUrStFKpFFOnThUODg5CT09PVKtWTezcuVP4+voKBweHHMUAQAQEBKiUXbp0SbRr104UL15c6Ovri/Lly4uxY8eqbfvH9pcPSU9PF7///rto0KCBMDExETo6OsLBwUH07NlT7ZLZc+fOCS8vL2FkZCSKFi0qGjduLI4fP65SJ7vLv3P6Hr/7Hs2ePVvY29sLPT090aBBA3HhwgWVZR88eCC9PyYmJqJjx47i0aNHau9ldut+d16msLAw0aZNG2FnZyd0dXWFnZ2d6NKli9rlkp+7z2X1eWfl9u3b4ttvv5X2gVq1aomdO3eq1Mm8LDYkJCTL9b8f1/tycsm+EB+/LDarmN5v9/3PIi0tTSxfvly0bdtW+v4ULVpUVKtWTcycOVPtcvNMmr4sVoi3lxz7+/sLZ2dnoaurKywsLMTXX38tZs2aJd68eSOEEGLTpk2iWbNmwsrKSujq6opSpUoJPz8/8fjxY5W2li9fLkqXLi20tbU/Gue6detE586dRZkyZYSBgYHQ19cXFStWFKNHj5YusX5XUFCQcHNzEwYGBqJYsWKicuXKYuTIkeLRo0dSndjYWNGqVStRrFgxASDfXCKrEELDI5eIiD7R3bt34eTkhJkzZ+Lnn3/O63CISIM4hoOIiIhkx4SDiIiIZMeEg4iIiGSXpwlHeHg4vL29YWdnB4VCoXZrbiEExo0bB1tbWxgYGMDT01PtOvv4+Hh07doVxsbGKF68OHr37v3JVwb81yQnJ2Po0KHSEzm//vprladYZj5p8P3XzJkzP9ju4sWL4ejoCH19fdSuXRunTp1SmT98+HCYmZnB3t5e7SY2ISEhn3QpHhUOjo6OEEJw/AZRIZSnCUdKSgpcXV2xePHiLOfPmDEDCxYswNKlSxEREQFDQ0N4eXmp3Oq2a9euuHz5Mvbt24edO3ciPDwc/fr1+1KbUKD16dMH+/btw59//omoqCg0a9YMnp6e0v0PHj9+rPJauXIlFAoFOnTokG2bGzZswPDhwxEQEIBz587B1dUVXl5e0m13d+zYgbVr12Lv3r2YMWMG+vTpg2fPngF4ezvq0aNHZ7s/EBFRAZa3F8n8DwCxdetWaVqpVAobGxuVS8oSEhKEnp6eWLdunRBCiCtXrqhddrV7926hUCjEw4cPv1jsBdHLly+Ftra22iV21atXF6NHj85ymTZt2ogmTZp8sN1atWqpXCaXkZEh7OzsRGBgoBBCiOnTp4tOnTpJ862srMSpU6eEEEL069dPzJkz55O2h4iI8rd8e+Ov6OhoxMbGqtxq1sTEBLVr18aJEyfQuXNnnDhxAsWLF1e5aZSnpye0tLQQERGBdu3aZdl2amqqdFc44H9P+DQ3N8+3t4TVtOTkZGRkZCAjI0PlSZ+6uro4fPiw2tM/nzx5gl27dmHp0qVq8zK9efMGZ8+exZAhQ1TquLu748iRI/jxxx/h7OyMpUuX4t69e7h79y5evXoFKysr7NmzB6dPn8a0adOybZ+IiPIfIQSSk5NhZ2f3wRvS5duEIzY2FgBgbW2tUm5tbS3Ni42NVbt7W5EiRWBmZibVyUpgYCAmTJig4YgLpjZt2mRZnvl0z/f16dNH5THuWenatetH28x8Jsb7/zczM/tg20RElD/dv38fJUuWzHZ+vk045OTv74/hw4dL04mJiShVqhTu37+v8WdC5Gd37tzBwIEDcezYMWhra8PV1RXOzs6IjIxUGTwKvH2QUOPGjT84YPTx48eoUKEC9u3bh1q1aknlY8eOxbFjx3DgwIEsl5s2bRoSExPRtWtXtGvXDidOnEBoaCiCgoIQHh6umY0lIiJZJCUlwd7e/qO39c+3CYeNjQ2Atw+IsrW1lcrj4uKkhynZ2NhIgxEzpaenIz4+Xlo+K3p6etDT01MrNzY2/k8lHFWrVsXRo0eRkpKCpKQk2NraolOnTnB2dlZ5H44cOSLdr/9D74++vj60tbXx4sULlXoJCQkoUaJElsteu3YNISEhOH/+PFauXAl3d3eULl0avr6+GDBgABQKxRd5HgoREX2ejw1JyLf34XBycoKNjY3Kk/SSkpIQERGBunXrAgDq1q2LhIQEnD17Vqpz4MABKJVK1K5d+4vHXFAZGhrC1tYWz58/x549e9ROs6xYsQJubm5wdXX9YDu6urpwc3NT+cyUSiXCwsKkz+xdQgj4+flhzpw5MDIyQkZGBtLS0gBA+jcjI+NzN4+IiPKBPO3hePHiBW7duiVNR0dHIzIyEmZmZihVqhSGDh2KyZMno2zZsnBycsLYsWNhZ2eHtm3bAgBcXFzQvHlz9O3bF0uXLkVaWhoGDhyIzp07w87OLo+2quDYs2cPhBAoX748bt26hREjRqBChQro2bOnVCcpKQkhISGYPXt2lm14eHigXbt2GDhwIIC399jw9fVFjRo1UKtWLcybNw8pKSkqbWb6/fffYWlpKd13o169ehg/fjxOnjyJ3bt3o2LFiihevLjmN5yIiL68vLxE5t0nCr778vX1FUK8vTR27NixwtraWujp6QkPDw9x/fp1lTb+/fdf0aVLF2FkZCSMjY1Fz549RXJycq7iSExMFABUnlr6X7BhwwZRunRpoaurK2xsbMSAAQNEQkKCSp1ly5YJAwMDtfJMDg4Oak+9XLhwoShVqpTQ1dUVtWrVEidPnlRbLjY2Vjg4OKhdvjxhwgRhZmYmKlSoICIiIj5vA4mISHY5/RvKp8Xi7a94ExMTJCYm/qfGcBAREX2unP4NzbdjOIiIiKjwYMJBREREsmPCQURERLLLt/fhKAwcf92V1yGQzO5Oa5XXIRARFQjs4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICIiItkx4SAiIiLZMeEgIiIi2THhICKiAiEjIwNjx46Fk5MTDAwMUKZMGUyaNAlCCKnOli1b0KxZM5ibm0OhUCAyMvKj7aalpWHixIkoU6YM9PX14erqitDQUJU6a9asgb29PUxNTTF8+HCVeXfv3kW5cuWQlJSkke0srIrkdQBEREQ5MX36dCxZsgSrV69GpUqVcObMGfTs2RMmJiYYPHgwACAlJQX169eHj48P+vbtm6N2x4wZg7/++gvLly9HhQoVsGfPHrRr1w7Hjx9HtWrV8OzZM/Tp0werVq1C6dKl0apVKzRp0gStW7cGAPz444+YNm0ajI2NZdv2woAJBxERFQjHjx9HmzZt0KpVKwCAo6Mj1q1bh1OnTkl1unXrBuBtr0NO/fnnnxg9ejRatmwJAOjfvz/279+P2bNn46+//sKdO3dgYmKCTp06AQAaN26Mq1evonXr1li3bh10dHTQvn17DW1l4cVTKkREVCB8/fXXCAsLw40bNwAAFy5cwNGjR9GiRYvPajc1NRX6+voqZQYGBjh69CgAoGzZsnj58iXOnz+P+Ph4nD59GlWqVMHz588xduxYLFq06LPW/1/BHg4iIioQfv31VyQlJaFChQrQ1tZGRkYGpkyZgq5du35Wu15eXpgzZw4aNmyIMmXKICwsDFu2bEFGRgYAwNTUFKtXr0b37t3x6tUrdO/eHV5eXujduzcGDhyI6OhofPPNN0hLS8P48ePx7bffamJzCx0mHEREVCBs3LgRa9aswdq1a1GpUiVERkZi6NChsLOzg6+v7ye3O3/+fPTt2xcVKlSAQqFAmTJl0LNnT6xcuVKq065dO7Rr106aPnz4MC5evIiFCxfC2dkZ69atg42NDWrVqoWGDRvCysrqs7a1MOIpFSIiKhBGjBiBX3/9FZ07d0blypXRrVs3DBs2DIGBgZ/VrqWlJbZt24aUlBTcu3cP165dg5GREUqXLp1l/dTUVPz4449YtmwZbt26hfT0dLi7u6N8+fIoV64cIiIiPiuewooJBxERFQgvX76Elpbqny1tbW0olUqNtK+vr48SJUogPT0dmzdvRps2bbKsN3nyZDRv3hzVq1dHRkYG0tPTpXlpaWnSqRhSxVMqRERUIHh7e2PKlCkoVaoUKlWqhPPnz2POnDno1auXVCc+Ph4xMTF49OgRAOD69esAABsbG9jY2AAAunfvjhIlSkg9IxEREXj48CGqVq2Khw8fYvz48VAqlRg5cqRaDFeuXMGGDRtw/vx5AECFChWgpaWFFStWwMbGBteuXUPNmjVlfR8KKiYcRERUICxcuBBjx47Fjz/+iCdPnsDOzg5+fn4YN26cVGf79u3o2bOnNN25c2cAQEBAAMaPHw8AiImJUekpef36NcaMGYM7d+7AyMgILVu2xJ9//onixYurrF8IgX79+mHOnDkwNDQE8PZqllWrVmHAgAFITU3FokWLUKJECZnegYJNId69Rdt/VFJSEkxMTJCYmKjRG7c4/rpLY21R/nR3Wqu8DoGIKE/l9G8ox3AQkUY5OjpCoVCovQYMGAAAiI2NRbdu3WBjYwNDQ0NUr14dmzdv/mCbS5YsQZUqVWBsbAxjY2PUrVsXu3fvVqkzfPhwmJmZwd7eHmvWrFGZFxISAm9vb81uKBHlCk+pEJFGnT59WmXQ3KVLl9C0aVN07NgRwNvz5wkJCdi+fTssLCywdu1a+Pj44MyZM6hWrVqWbZYsWRLTpk1D2bJlIYTA6tWr0aZNG5w/fx6VKlXCjh07sHbtWuzduxc3b95Er1694OXlBQsLCyQmJmL06NHYv3//F9l+IsoaEw4i0ihLS0uV6WnTpqFMmTJwd3cH8Pb21EuWLEGtWrUAvH2Oxdy5c3H27NlsE473eyemTJmCJUuW4OTJk6hUqRKuXr2KRo0aoUaNGqhRowaGDh2K6OhoWFhYYOTIkejfvz9KlSolw9YWPjwVXPjl1angfH1KJSdPBhRCYNy4cbC1tYWBgQE8PT1x8+bNPIyaiDK9efMGf/31F3r16gWFQgHg7e2pN2zYgPj4eCiVSqxfvx6vX79Go0aNctRmRkYG1q9fj5SUFNStWxcA4OrqijNnzuD58+c4e/YsXr16BWdnZxw9ehTnzp2THuxFRHknXyccmU8GXLRoEa5evYrp06djxowZWLhwoVRnxowZWLBgAZYuXYqIiAgYGhrCy8sLr1+/zsPIiQgAtm3bhoSEBPTo0UMq27hxI9LS0mBubg49PT34+flh69atcHZ2/mBbUVFRMDIygp6eHn744Qds3boVFStWBPD21tTff/89atasiR49emD16tUwNDRE//79sXTpUixZsgTly5dHvXr1cPnyZTk3mYiyka9PqXzsyYBCCMybNw9jxoyRbtDyxx9/wNraGtu2bZMuhyKivLFixQq0aNECdnZ2UtnYsWORkJCA/fv3w8LCAtu2bYOPjw+OHDmCypUrZ9tW+fLlERkZicTERGzatAm+vr44fPiwlHSMHz9euuwRACZMmABPT0/o6Ohg8uTJiIqKws6dO9G9e3ecPXtWtm0moqzl6x6Ojz0ZMDo6GrGxsfD09JSWMTExQe3atXHixIk8iZmI3rp37x7279+PPn36SGW3b9/GokWLsHLlSnh4eMDV1RUBAQGoUaMGFi9e/MH2dHV14ezsDDc3NwQGBsLV1RXz58/Psu61a9fw119/YdKkSTh06BAaNmwIS0tL+Pj44Ny5c0hOTtbothLRx+XrHo6PPRkwNjYWAGBtba2ynLW1tTQvK6mpqUhNTZWmk5KSZIie6L8tODgYVlZWUg8l8PbW1AA0cntqpVKp8j3OJISAn58f5syZAyMjI2RkZCAtLQ0ApH9562miLy9f93C8+2TAc+fOYfXq1Zg1axZWr179We0GBgbCxMREetnb22soYiIC3iYDwcHB8PX1RZEi//tdU6FCBTg7O8PPzw+nTp3C7du3MXv2bOzbtw9t27aV6nl4eGDRokXStL+/P8LDw3H37l1ERUXB398fhw4dyvKx5L///jssLS2lK1vq1auHAwcO4OTJk5g7dy4qVqyodgdJIpJfvu7hePfJgABQuXJl3Lt3D4GBgfD19ZXuix8XFwdbW1tpubi4OFStWjXbdv39/TF8+HBpOikpiUkHkQbt378fMTExKs+4AAAdHR38888/+PXXX+Ht7Y0XL17A2dkZq1evRsuWLaV6t2/fxrNnz6TpJ0+eoHv37nj8+DFMTExQpUoV7NmzB02bNlVpPy4uDlOmTMHx48elslq1auGnn35Cq1atYGVl9dk/WIjo0+TrhONjTwZ0cnKCjY0NwsLCpAQjKSkJERER6N+/f7bt6unpQU9PT7a4if7rmjVrhuyemlC2bNmP3ln07t27KtMrVqzI0Xqtra3VlgWAcePGqTxvg4i+vHydcHzsyYAKhQJDhw7F5MmTUbZsWTg5OWHs2LGws7NT6Z4lIiKivJWvE46cPBlw5MiRSElJQb9+/ZCQkID69esjNDQU+vr6eRg5ERERvYtPiwWfFkufLq9uEcx9q/DjvkVy0fS+xafFEhERUb7BhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZMeEg4iIiGTHhIOIiIhkx4SDiIiIZFckN5WVSiUOHz6MI0eO4N69e3j58iUsLS1RrVo1eHp6wt7eXq44iYiIqADLUQ/Hq1evMHnyZNjb26Nly5bYvXs3EhISoK2tjVu3biEgIABOTk5o2bIlTp48KXfMREREVMDkqIejXLlyqFu3LpYvX46mTZtCR0dHrc69e/ewdu1adO7cGaNHj0bfvn01HiwREREVTDlKOPbu3QsXF5cP1nFwcIC/vz9+/vlnxMTEaCQ4IiIiKhxydErlY8nGu3R0dFCmTJlPDoiIiIgKn1wNGn1Xeno6li1bhkOHDiEjIwP16tXDgAEDoK+vr8n4iIiIqBD45IRj8ODBuHHjBtq3b4+0tDT88ccfOHPmDNatW6fJ+IiIiKgQyHHCsXXrVrRr106a3rt3L65fvw5tbW0AgJeXF+rUqaP5CImIiKjAy/GNv1auXIm2bdvi0aNHAIDq1avjhx9+QGhoKHbs2IGRI0eiZs2asgVKREREBVeOE44dO3agS5cuaNSoERYuXIigoCAYGxtj9OjRGDt2LOzt7bF27VqNB/jw4UN8//33MDc3h4GBASpXrowzZ85I84UQGDduHGxtbWFgYABPT0/cvHlT43EQERHRp8vVrc07deqEU6dOISoqCl5eXvj+++9x9uxZREZGYvHixbC0tNRocM+fP0e9evWgo6OD3bt348qVK5g9ezZMTU2lOjNmzMCCBQuwdOlSREREwNDQEF5eXnj9+rVGYyEiIqJPl+tBo8WLF0dQUBDCw8PRvXt3NG/eHJMmTZLl6pTp06fD3t4ewcHBUpmTk5P0fyEE5s2bhzFjxqBNmzYAgD/++APW1tbYtm0bOnfurPGYiIiIKPdy3MMRExMDHx8fVK5cGV27dkXZsmVx9uxZFC1aFK6urti9e7fGg9u+fTtq1KiBjh07wsrKCtWqVcPy5cul+dHR0YiNjYWnp6dUZmJigtq1a+PEiRPZtpuamoqkpCSVFxEREcknxwlH9+7doaWlhZkzZ8LKygp+fn7Q1dXFhAkTsG3bNgQGBsLHx0ejwd25cwdLlixB2bJlsWfPHvTv3x+DBw/G6tWrAQCxsbEAAGtra5XlrK2tpXlZCQwMhImJifTiQ+eIiIjkleNTKmfOnMGFCxdQpkwZeHl5qZzacHFxQXh4OIKCgjQanFKpRI0aNTB16lQAQLVq1XDp0iUsXboUvr6+n9yuv78/hg8fLk0nJSUx6SAiIpJRjns43NzcMG7cOOzduxe//PILKleurFanX79+Gg3O1tYWFStWVClzcXGRntViY2MDAIiLi1OpExcXJ83Lip6eHoyNjVVeREREJJ8cJxx//PEHUlNTMWzYMDx8+BDLli2TMy4AQL169XD9+nWVshs3bsDBwQHA2wGkNjY2CAsLk+YnJSUhIiICdevWlT0+IiIiypkcn1JxcHDApk2b5IxFzbBhw/D1119j6tSp8PHxwalTpxAUFCSdulEoFBg6dCgmT56MsmXLwsnJCWPHjoWdnR3atm37RWMlIiKi7OUo4UhJSYGhoWGOG81t/ezUrFkTW7duhb+/PyZOnAgnJyfMmzcPXbt2leqMHDkSKSkp6NevHxISElC/fn2EhobyIXJERET5SI5OqTg7O2PatGl4/PhxtnWEENi3bx9atGiBBQsWaCzA1q1bIyoqCq9fv8bVq1fRt29flfkKhQITJ05EbGwsXr9+jf3796NcuXIaWz8RERF9vhz1cBw6dAijRo3C+PHj4erqiho1asDOzg76+vp4/vw5rly5ghMnTqBIkSLw9/eHn5+f3HETERFRAZKjhKN8+fLYvHkzYmJiEBISgiNHjuD48eN49eoVLCwspBtytWjRQnp6LBEREVGmXN3avFSpUvjpp5/w008/yRUPERERFUK5engbERER0adgwkFERESyY8JBREREsmPCQURERLJjwkFERESyy3XC4ejoiIkTJ0oPUCMiIiL6mFwnHEOHDsWWLVtQunRpNG3aFOvXr0dqaqocsREREVEh8UkJR2RkJE6dOgUXFxcMGjQItra2GDhwIM6dOydHjERERFTAffIYjurVq2PBggV49OgRAgIC8Pvvv6NmzZqoWrUqVq5cCSGEJuMkIiKiAixXdxp9V1paGrZu3Yrg4GDs27cPderUQe/evfHgwQOMGjUK+/fvx9q1azUZKxERERVQuU44zp07h+DgYKxbtw5aWlro3r075s6diwoVKkh12rVrh5o1a2o0UCIiIiq4cp1w1KxZE02bNsWSJUvQtm1b6OjoqNVxcnJC586dNRIgERERFXy5Tjju3LkDBweHD9YxNDREcHDwJwdFREREhUuuB40+efIEERERauURERE4c+aMRoIiIiKiwiXXCceAAQNw//59tfKHDx9iwIABGgmKiIiICpdcJxxXrlxB9erV1cqrVauGK1euaCQoIiIiKlxynXDo6ekhLi5Orfzx48coUuSTr7IlIiKiQizXCUezZs3g7++PxMREqSwhIQGjRo1C06ZNNRocERERFQ657pKYNWsWGjZsCAcHB1SrVg0AEBkZCWtra/z5558aD5CIiIgKvlwnHCVKlMDFixexZs0aXLhwAQYGBujZsye6dOmS5T05iIiIiD5p0IWhoSH69eun6ViIiIiokPrkUZ5XrlxBTEwM3rx5o1L+zTfffHZQREREVLh80p1G27Vrh6ioKCgUCumpsAqFAgCQkZGh2QiJiIiowMv1VSpDhgyBk5MTnjx5gqJFi+Ly5csIDw9HjRo1cOjQIRlCJCIiooIu1z0cJ06cwIEDB2BhYQEtLS1oaWmhfv36CAwMxODBg3H+/Hk54iQiIqICLNc9HBkZGShWrBgAwMLCAo8ePQIAODg44Pr165qNjoiIiAqFXPdwfPXVV7hw4QKcnJxQu3ZtzJgxA7q6uggKCkLp0qXliJGIiIgKuFwnHGPGjEFKSgoAYOLEiWjdujUaNGgAc3NzbNiwQeMBEhERUcGX64TDy8tL+r+zszOuXbuG+Ph4mJqaSleqEBEREb0rV2M40tLSUKRIEVy6dEml3MzMjMkGERERZStXCYeOjg5KlSrFe20QERFRruT6KpXRo0dj1KhRiI+PlyMeIiIiKoRyPYZj0aJFuHXrFuzs7ODg4ABDQ0OV+efOndNYcERERFQ45DrhaNu2rQxhEBERUWGW64QjICBAjjiIiIioEMv1GA4iIiKi3Mp1D4eWltYHL4HlFSxERET0vlwnHFu3blWZTktLw/nz57F69WpMmDBBY4ERERFR4ZHrhKNNmzZqZd9++y0qVaqEDRs2oHfv3hoJjIiIiAoPjY3hqFOnDsLCwjTVHBERERUiGkk4Xr16hQULFqBEiRKaaI6IiIgKmVyfUnn/IW1CCCQnJ6No0aL466+/NBocERERFQ65Tjjmzp2rknBoaWnB0tIStWvXhqmpqUaDIyIiosIh1wlHjx49ZAiDiIiICrNcj+EIDg5GSEiIWnlISAhWr16tkaCIiIiocMl1whEYGAgLCwu1cisrK0ydOlUjQREREVHhkuuEIyYmBk5OTmrlDg4OiImJ0UhQREREVLjkOuGwsrLCxYsX1covXLgAc3NzjQRFREREhUuuE44uXbpg8ODBOHjwIDIyMpCRkYEDBw5gyJAh6Ny5sxwxSqZNmwaFQoGhQ4dKZa9fv8aAAQNgbm4OIyMjdOjQAXFxcbLGQURERLmT64Rj0qRJqF27Njw8PGBgYAADAwM0a9YMTZo0kXUMx+nTp7Fs2TJUqVJFpXzYsGHYsWMHQkJCcPjwYTx69Ajt27eXLQ4iIiLKvVxfFqurq4sNGzZg8uTJiIyMhIGBASpXrgwHBwc54gMAvHjxAl27dsXy5csxefJkqTwxMRErVqzA2rVr0aRJEwBvr6JxcXHByZMnUadOHdliIiIiopzLdcKRqWzZsihbtqwmY8nWgAED0KpVK3h6eqokHGfPnkVaWho8PT2lsgoVKqBUqVI4ceJEtglHamoqUlNTpemkpCT5giciIqLcn1Lp0KEDpk+frlY+Y8YMdOzYUSNBvWv9+vU4d+4cAgMD1ebFxsZCV1cXxYsXVym3trZGbGxstm0GBgbCxMREetnb22s6bCIiInpHrhOO8PBwtGzZUq28RYsWCA8P10hQme7fv48hQ4ZgzZo10NfX11i7/v7+SExMlF7379/XWNtERESkLtcJx4sXL6Crq6tWrqOjo/FTE2fPnsWTJ09QvXp1FClSBEWKFMHhw4exYMECFClSBNbW1njz5g0SEhJUlouLi4ONjU227erp6cHY2FjlRURERPLJdcJRuXJlbNiwQa18/fr1qFixokaCyuTh4YGoqChERkZKrxo1aqBr167S/3V0dBAWFiYtc/36dcTExKBu3boajYWIiIg+Xa4HjY4dOxbt27fH7du3pStDwsLCsG7duiyfsfI5ihUrhq+++kqlzNDQEObm5lJ57969MXz4cJiZmcHY2BiDBg1C3bp1eYUKERFRPpLrhMPb2xvbtm3D1KlTsWnTJhgYGKBKlSrYv38/3N3d5Yjxg+bOnQstLS106NABqamp8PLywm+//fbF4yAiIqLsfdJlsa1atUKrVq3Uyi9duqTWI6Fphw4dUpnW19fH4sWLsXjxYlnXS0RERJ8u12M43pecnIygoCDUqlULrq6umoiJiIiICplPTjjCw8PRvXt32NraYtasWWjSpAlOnjypydiIiIiokMjVKZXY2FisWrUKK1asQFJSEnx8fJCamopt27Zp/AoVIiIiKjxy3MPh7e2N8uXL4+LFi5g3bx4ePXqEhQsXyhkbERERFRI57uHYvXs3Bg8ejP79+3+xZ6gQERFR4ZDjHo6jR48iOTkZbm5uqF27NhYtWoRnz57JGRsREREVEjlOOOrUqYPly5fj8ePH8PPzw/r162FnZwelUol9+/YhOTlZzjiJiIioAMv1VSqGhobo1asXjh49iqioKPz000+YNm0arKys8M0338gRIxERERVwn3UfjvLly2PGjBl48OAB1q1bp6mYiIiIqJD57Bt/AYC2tjbatm2L7du3a6I5IiIiKmQ0knAQERERfQgTDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikh0TDiIiIpIdEw4iIiKSHRMOIiIikl2+TjgCAwNRs2ZNFCtWDFZWVmjbti2uX7+uUuf169cYMGAAzM3NYWRkhA4dOiAuLi6PIiYiIqKs5OuE4/DhwxgwYABOnjyJffv2IS0tDc2aNUNKSopUZ9iwYdixYwdCQkJw+PBhPHr0CO3bt8/DqImIiOh9RfI6gA8JDQ1VmV61ahWsrKxw9uxZNGzYEImJiVixYgXWrl2LJk2aAACCg4Ph4uKCkydPok6dOnkRNhEREb0nX/dwvC8xMREAYGZmBgA4e/Ys0tLS4OnpKdWpUKECSpUqhRMnTuRJjERERKQuX/dwvEupVGLo0KGoV68evvrqKwBAbGwsdHV1Ubx4cZW61tbWiI2Nzbat1NRUpKamStNJSUmyxExERERvFZgejgEDBuDSpUtYv379Z7cVGBgIExMT6WVvb6+BCImIiCg7BSLhGDhwIHbu3ImDBw+iZMmSUrmNjQ3evHmDhIQElfpxcXGwsbHJtj1/f38kJiZKr/v378sVOhERESGfJxxCCAwcOBBbt27FgQMH4OTkpDLfzc0NOjo6CAsLk8quX7+OmJgY1K1bN9t29fT0YGxsrPIiIiIi+eTrMRwDBgzA2rVr8ffff6NYsWLSuAwTExMYGBjAxMQEvXv3xvDhw2FmZgZjY2MMGjQIdevW5RUqRERE+Ui+TjiWLFkCAGjUqJFKeXBwMHr06AEAmDt3LrS0tNChQwekpqbCy8sLv/322xeOlIiIiD4kXyccQoiP1tHX18fixYuxePHiLxARERERfYp8PYaDiIiICgcmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQkOyYcREREJDsmHERERCQ7JhxEREQku0KTcCxevBiOjo7Q19dH7dq1cerUqbwOiYiIiP5foUg4NmzYgOHDhyMgIADnzp2Dq6srvLy88OTJk7wOjYiIiFBIEo45c+agb9++6NmzJypWrIilS5eiaNGiWLlyZV6HRkRERACK5HUAn+vNmzc4e/Ys/P39pTItLS14enrixIkTWS6TmpqK1NRUaToxMREAkJSUpNHYlKkvNdoe5T+a3mdyivtW4cd9i+Si6X0rsz0hxAfrFfiE49mzZ8jIyIC1tbVKubW1Na5du5blMoGBgZgwYYJaub29vSwxUuFlMi+vI6DCivsWyUWufSs5ORkmJibZzi/wCcen8Pf3x/Dhw6VppVKJ+Ph4mJubQ6FQ5GFkBVdSUhLs7e1x//59GBsb53U4VIhw3yK5cN/SDCEEkpOTYWdn98F6BT7hsLCwgLa2NuLi4lTK4+LiYGNjk+Uyenp60NPTUykrXry4XCH+pxgbG/OLS7LgvkVy4b71+T7Us5GpwA8a1dXVhZubG8LCwqQypVKJsLAw1K1bNw8jIyIiokwFvocDAIYPHw5fX1/UqFEDtWrVwrx585CSkoKePXvmdWhERESEQpJwdOrUCU+fPsW4ceMQGxuLqlWrIjQ0VG0gKclHT08PAQEBaqeqiD4X9y2SC/etL0shPnYdCxEREdFnKvBjOIiIiCj/Y8JBREREsmPCQURERLJjwkFqGjVqhKFDh0rTjo6OmDdvXp7FQ4WTQqHAtm3b8joMyic+d38YP348qlatKk336NEDbdu2labfP659ilWrVvGeTZ+BCUch1KNHDygUCrXXrVu3ZFnf+PHjpXUUKVIEFhYWaNiwIebNm6fyzJqcOHToEBQKBRISEmSJlf7n3f1ER0cHTk5OGDlyJF6/fp3XockqPDwc3t7esLOzy/aPnBAC48aNg62tLQwMDODp6YmbN2+q1ImPj0fXrl1hbGyM4sWLo3fv3njx4sUX2oqC4f19zNraGk2bNsXKlSuhVCpV6j5+/BgtWrTIUbtZfW4///yzyv2Y8srhw4fRpEkTmJmZoWjRoihbtix8fX3x5s2bHLdRWH/kMeEopJo3b47Hjx+rvJycnGRbX6VKlfD48WPExMTg4MGD6NixIwIDA/H1118jOTlZtvXS58ncT+7cuYO5c+di2bJlCAgIyOuwZJWSkgJXV1csXrw42zozZszAggULsHTpUkRERMDQ0BBeXl4qyVjXrl1x+fJl7Nu3Dzt37kR4eDj69ev3JTahQMncx+7evYvdu3ejcePGGDJkCFq3bo309HSpno2NzWddnmpkZARzc3NNhPzJrly5gubNm6NGjRoIDw9HVFQUFi5cCF1dXWRkZORpbPmCoELH19dXtGnTJsfzhgwZItzd3aVpd3d3MWTIEGnawcFBzJ07N9v1BQQECFdXV7Xyq1evCl1dXTF69Gip7I8//hBubm7CyMhIWFtbiy5duoi4uDghhBDR0dECgMrL19dXCCHE7t27Rb169YSJiYkwMzMTrVq1Erdu3frQ20AfkdW+0L59e1GtWjVp+tmzZ6Jz587Czs5OGBgYiK+++kqsXbtWZRl3d3cxaNAgMWLECGFqaiqsra1FQECASp0bN26IBg0aCD09PeHi4iL27t0rAIitW7dKdS5evCgaN24s9PX1hZmZmejbt69ITk5Wi3fKlCnCyspKmJiYiAkTJoi0tDTx888/C1NTU1GiRAmxcuXKHL8H78cghBBKpVLY2NiImTNnSmUJCQlCT09PrFu3TgghxJUrVwQAcfr0aanO7t27hUKhEA8fPszx+gu77I5FYWFhAoBYvny5VPbuZ5GamioGDBggbGxshJ6enihVqpSYOnWqEOLt8ejdY4SDg4MQQv049P663z+uvX79Wvz000/Czs5OFC1aVNSqVUscPHhQJc7g4GBhb28vDAwMRNu2bcWsWbOEiYlJtts7d+5c4ejo+NH35ciRI6J+/fpCX19flCxZUgwaNEi8ePFCivP942BhwR4Okk2FChXQokULbNmyRSpLS0vDpEmTcOHCBWzbtg13795Fjx49ALx9Wu/mzZsBANevX8fjx48xf/58AG9/lQ4fPhxnzpxBWFgYtLS00K5dO7VuWfp0ly5dwvHjx6GrqyuVvX79Gm5ubti1axcuXbqEfv36oVu3bjh16pTKsqtXr4ahoSEiIiIwY8YMTJw4Efv27QPw9lED7du3h66uLiIiIrB06VL88ssvKsunpKTAy8sLpqamOH36NEJCQrB//34MHDhQpd6BAwfw6NEjhIeHY86cOQgICEDr1q1hamqKiIgI/PDDD/Dz88ODBw8++X2Ijo5GbGwsPD09pTITExPUrl0bJ06cAACcOHECxYsXR40aNaQ6np6e0NLSQkRExCev+7+iSZMmcHV1VTk2vGvBggXYvn07Nm7ciOvXr2PNmjVwdHQEAJw+fRoAEBwcjMePH0vTuTVw4ECcOHEC69evx8WLF9GxY0c0b95cOnUWERGB3r17Y+DAgYiMjETjxo0xefLkD7ZpY2ODx48fIzw8PNs6t2/fRvPmzdGhQwdcvHgRGzZswNGjR6V9fcuWLShZsiQmTpwo9U4XGnmd8ZDm+fr6Cm1tbWFoaCi9vv32W2nel+rhEEKIX375RRgYGGS77OnTpwUA6ZfswYMHBQDx/PnzD22iePr0qQAgoqKiPliPsvfufqKnpycACC0tLbFp06YPLteqVSvx008/SdPu7u6ifv36KnVq1qwpfvnlFyGEEHv27BFFihRR+eW/e/dulV+0QUFBwtTUVPqVJ4QQu3btElpaWiI2NlaK18HBQWRkZEh1ypcvLxo0aCBNp6enC0NDQ6kn4mOQRQ/HsWPHBADx6NEjlfKOHTsKHx8fIYQQU6ZMEeXKlVNrz9LSUvz22285Wvd/wYd6Wzt16iRcXFyk6Xc/i0GDBokmTZoIpVKZ5bJZfW656eG4d++e0NbWVuuN8vDwEP7+/kIIIbp06SJatmypFvOHejjS09NFjx49BABhY2Mj2rZtKxYuXCgSExOlOr179xb9+vVTWe7IkSNCS0tLvHr1Sgjx8WNuQcUejkKqcePGiIyMlF4LFizIkziEEFAoFNL02bNn4e3tjVKlSqFYsWJwd3cHAMTExHywnZs3b6JLly4oXbo0jI2NpV87H1uOPixzP4mIiICvry969uyJDh06SPMzMjIwadIkVK5cGWZmZjAyMsKePXvU3vcqVaqoTNva2uLJkycAgKtXr8Le3l7l0dXvP1jx6tWrcHV1haGhoVRWr149KJVKXL9+XSqrVKkStLT+d9iytrZG5cqVpWltbW2Ym5tL66b86/1jw7t69OiByMhIlC9fHoMHD8bevXs1uu6oqChkZGSgXLlyMDIykl6HDx/G7du3AbzdJ2vXrq2y3MceCKqtrY3g4GA8ePAAM2bMQIkSJTB16lRpjBsAXLhwAatWrVJZr5eXF5RKJaKjozW6nflNoXiWCqkzNDSEs7OzWrmWlhbEe3ezT0tLky2Oq1evSoNVM7vNvby8sGbNGlhaWiImJgZeXl4fHcHt7e0NBwcHLF++HHZ2dlAqlfjqq69yNfKb1L27n6xcuRKurq5YsWIFevfuDQCYOXMm5s+fj3nz5qFy5cowNDTE0KFD1d53HR0dlWmFQiHL6a6s1qPpddvY2AAA4uLiYGtrK5XHxcVJl13a2NioJTXp6emIj4+XlqcPe/fY8L7q1asjOjoau3fvxv79++Hj4wNPT09s2rRJI+t+8eIFtLW1cfbsWWhra6vMMzIy+uz2S5QogW7duqFbt26YNGkSypUrh6VLl2LChAl48eIF/Pz8MHjwYLXlSpUq9dnrzs/Yw/EfY2lpqXZOMDIyUpZ1Xbt2DaGhodIv5mvXruHff//FtGnT0KBBA1SoUEHtoJ05fuDdEd3//vsvrl+/jjFjxsDDwwMuLi54/vy5LDH/l2lpaWHUqFEYM2YMXr16BQA4duwY2rRpg++//x6urq4oXbo0bty4kat2XVxccP/+fZX97uTJk2p1Lly4gJSUFKns2LFj0NLSQvny5T9jq3LPyckJNjY2KpdYJiUlISIiQvqFW7duXSQkJODs2bNSnQMHDkCpVKr9KiZ1Bw4cQFRUlEpv2vuMjY3RqVMnLF++HBs2bMDmzZsRHx8P4G3i+TlXfVSrVg0ZGRl48uQJnJ2dVV6ZCaOLi4vaeJz399ucMDU1ha2trbRvV69eHVeuXFFbr7Ozs3T8K6xXtTDh+I9p0qQJzpw5gz/++AM3b95EQEAALl269NntpqenIzY2Fo8ePZIuBXN3d0fVqlUxYsQIAG+zd11dXSxcuBB37tzB9u3bMWnSJJV2HBwcoFAosHPnTjx9+hQvXryAqakpzM3NERQUhFu3buHAgQMYPnz4Z8dM6jp27AhtbW3pktGyZcti3759OH78OK5evQo/Pz/ExcXlqk1PT0+UK1cOvr6+uHDhAo4cOYLRo0er1OnatSv09fXh6+uLS5cu4eDBgxg0aBC6deum8ac+v3jxQjrVCLwdJBoZGSmdJlIoFBg6dCgmT56M7du3IyoqCt27d4ednZ10IykXFxc0b94cffv2xalTp3Ds2DEMHDgQnTt3Vjl1REBqaipiY2Px8OFDnDt3DlOnTkWbNm3QunVrdO/ePctl5syZg3Xr1uHatWu4ceMGQkJCYGNjI910y9HREWFhYYiNjf2kHx/lypVD165d0b17d2zZsgXR0dE4deoUAgMDsWvXLgDA4MGDERoailmzZuHmzZtYtGgRQkNDP9jusmXL0L9/f+zduxe3b9/G5cuX8csvv+Dy5cvw9vYGAPzyyy84fvy4NBj15s2b+Pvvv1UGSDs6OiI8PBwPHz7Es2fPcr19+RUTjv8YLy8vjB07FiNHjkTNmjWRnJyc7Zc+Ny5fvgxbW1uUKlUKjRo1wsaNG+Hv748jR45IXZSWlpZYtWoVQkJCULFiRUybNg2zZs1SaadEiRKYMGECfv31V1hbW2PgwIHQ0tLC+vXrcfbsWXz11VcYNmwYZs6c+dkxk7oiRYpg4MCBmDFjBlJSUjBmzBhUr14dXl5eaNSoEWxsbFTu3pgTWlpa2Lp1K169eoVatWqhT58+mDJlikqdokWLYs+ePYiPj0fNmjXx7bffwsPDA4sWLdLg1r115swZVKtWDdWqVQMADB8+HNWqVcO4ceOkOiNHjsSgQYPQr18/1KxZEy9evEBoaCj09fWlOmvWrEGFChXg4eGBli1bon79+ggKCtJ4vAVdaGgobG1t4ejoiObNm+PgwYNYsGAB/v77b7XTGZmKFSuGGTNmoEaNGqhZsybu3r2Lf/75Rxq/M3v2bOzbtw/29vbS55hbwcHB6N69O3766SeUL18ebdu2xenTp6XTGnXq1MHy5csxf/58uLq6Yu/evRgzZswH26xVqxZevHiBH374AZUqVYK7uztOnjyJbdu2SePVqlSpgsOHD+PGjRto0KCBtO+9m6hOnDgRd+/eRZkyZWBpaflJ25cf8fH0REREJDv2cBAREZHsmHAQERGR7JhwEBERkeyYcBAREZHsmHAQERGR7JhwEBERkeyYcBAREZHsmHAQERGR7JhwEBERkeyYcBAREZHsmHAQERGR7JhwEBERkez+D3GPWX7w/sRIAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "results = {\n",
        "    'Full Data': acc_full,\n",
        "    'Random 100': acc_small,\n",
        "    'Distilled Set': acc_distill,\n",
        "}\n",
        "\n",
        "for k, v in results.items():\n",
        "    print(f'{k:<12}: {v:5.2f}%')\n",
        "\n",
        "# Bar chart\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.bar(results.keys(), results.values())\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('LeNet Performance Comparison on MNIST Test Set')\n",
        "plt.ylim(0, 100)\n",
        "for i, v in enumerate(results.values()):\n",
        "    plt.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LvNzQGO8-fMD"
      },
      "id": "LvNzQGO8-fMD",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}